{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNIST 숫자이미지 분석, 우편물 분류를 위해 고안됌.\n",
    "## Kaggle 에도 데이터가 있고 텐서플로우 안에도 샘플로 데이터가 포함되어 있다.\n",
    "\n",
    "import tensorflow as tf #텐서플로우의 기본 기능인 그래프를 그리기위해 불러온 것.\n",
    "from tensorflow.examples.tutorials.mnist import input_data#텐서플로우 인풋데이터라는 함수를 이용해, tf내의 모듈 사용하기위해 불러온 것.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 가로 픽셀 세로 픽셀 각 픽셀의 색상, 이미지는 기본 3차원. 그러나 우리가 사용하는 것은 흑백으로 2차원데이터. 28x28 데이터. \n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)#원래는 원핫인코딩도 만들어야되는데 tf가 제공해줌.\n",
    "\n",
    "### plt.imshow(mnist.train.images[0].reshape(28, 28), cmap=\"Greys\")# 이미지쇼, 1차원으로 되어있으므로 이미지쇼를 하려면 2차원으로 리쉐잎해야한다. \n",
    "### mnist.train.images[0]# images가 이미지에 대한 데이터를 의미함. 레이블아님.\n",
    "\n",
    "### print(mnist.train.labels[0])\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "# Weight bias\n",
    "W = tf.Variable(tf.random_normal([784, 10]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.nn.softmax(logit)#멀티노미널이니까 소프트맥스 사용\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.09).minimize(cost)\n",
    "#경사하강법을 계속 써야 하는가? // 애덤 등 옵티마이저 다른 것도 있다. \n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "# 기존의 학습은 데이터가 적었기때문에 3000번 진행해도 괜찮았으나, 지금은 데이터가 커서 오래걸림. \n",
    "# 따라서 epoch 과 batch 에 대한 개념을 알아보자!!\n",
    "# epoch : 1 epoch 은 training data를 이용해서 1번 학습하는 것. 3000번은 많음으로 20번으로 수정\n",
    "train_epoch = 20\n",
    "batch_size = 100\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)# 배치 사이즈 만큼 원본에서 뜯어옴. \n",
    "        tmp_train, cost_val = sess.run([train, cost], feed_dict={X:batch_x, Y:batch_y})\n",
    "        \n",
    "    if step % 3 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "\n",
    "# 정확도 측정\n",
    "predict = tf.argmax(H, axis=1)\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels })) #원래는 이것도 배치 처리 해야댐.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
